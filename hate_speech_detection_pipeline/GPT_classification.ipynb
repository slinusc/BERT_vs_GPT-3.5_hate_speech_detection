{"cells":[{"cell_type":"code","outputs":[],"source":["from chat_GPT import Chat\n","import pandas as pd\n","from tqdm.auto import tqdm"],"metadata":{"collapsed":true,"ExecuteTime":{"end_time":"2024-03-21T12:13:33.221274Z","start_time":"2024-03-21T12:13:33.114116Z"},"id":"initial_id"},"id":"initial_id","execution_count":null},{"cell_type":"markdown","source":["Importing the test data"],"metadata":{"collapsed":false,"id":"a0bfa0e4e32dd1ef"},"id":"a0bfa0e4e32dd1ef"},{"cell_type":"code","outputs":[{"data":{"text/plain":"                 id                                       comment_text  label\n0  0001ea8717f6de06  Thank you for understanding I think very highl...      0\n1  000247e83dcc1211                     Dear god this site is horrible      0\n2  0002f87b16116a7f   Somebody will invariably try to add Religion ...      0\n3  0003e1cccfd5a40a      It says it right there that it IS a type T...      0\n4  00059ace3e3e9a53       Before adding a new product to the list m...      0\n5  000663aff0fffc80                               this other one from       0\n6  000689dd34e20979   Reason for banning throwing     This article ...      0\n7  000844b52dee5f3f                  blocked from editing Wikipedia         0\n8  00091c35fa9d0465   Arabs are committing genocide in Iraq but no ...      1\n9  000968ce11f5ee34  Please stop If you continue to vandalize Wikip...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001ea8717f6de06</td>\n      <td>Thank you for understanding I think very highl...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000247e83dcc1211</td>\n      <td>Dear god this site is horrible</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0002f87b16116a7f</td>\n      <td>Somebody will invariably try to add Religion ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003e1cccfd5a40a</td>\n      <td>It says it right there that it IS a type T...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00059ace3e3e9a53</td>\n      <td>Before adding a new product to the list m...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>000663aff0fffc80</td>\n      <td>this other one from</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>000689dd34e20979</td>\n      <td>Reason for banning throwing     This article ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>000844b52dee5f3f</td>\n      <td>blocked from editing Wikipedia</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00091c35fa9d0465</td>\n      <td>Arabs are committing genocide in Iraq but no ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>000968ce11f5ee34</td>\n      <td>Please stop If you continue to vandalize Wikip...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv(\"../data/test/clean_test.csv\")\n","data.head(10)"],"metadata":{"ExecuteTime":{"end_time":"2024-03-21T12:46:59.325462Z","start_time":"2024-03-21T12:46:59.100398Z"},"id":"76fc8e9d254db7f","outputId":"c39cfb3e-a9c1-480d-f7ae-455d934b3767"},"id":"76fc8e9d254db7f","execution_count":null},{"cell_type":"markdown","source":["Creating a subset of the data to test the GPT-3 model"],"metadata":{"collapsed":false,"id":"faba8c8445cef54a"},"id":"faba8c8445cef54a"},{"cell_type":"code","outputs":[],"source":["messages = data['comment_text'][0:1000].to_list()"],"metadata":{"ExecuteTime":{"end_time":"2024-03-21T12:10:36.283290Z","start_time":"2024-03-21T12:10:36.279314Z"},"id":"c800e9580ed61c51"},"id":"c800e9580ed61c51","execution_count":null},{"cell_type":"markdown","source":["## Classify the messages using GPT-3.5 turbo\n","\n","Importing the chat_GPT class and creating a chat object to classify the messages. We used chunks of 10 messages to reduce the number tokens per request to the API."],"metadata":{"collapsed":false,"id":"20fdc964c260d568"},"id":"20fdc964c260d568"},{"cell_type":"code","outputs":[],"source":["responses = []\n","chat = Chat()\n","\n","for i in tqdm(range(0, len(messages), 10)):\n","    chunk = messages[i:i+10]\n","    responses += chat.batch_create_chats(chunk)"],"metadata":{"ExecuteTime":{"end_time":"2024-03-21T12:21:07.542941Z","start_time":"2024-03-21T12:13:37.809745Z"},"id":"d02bc3837fe7fe96"},"id":"d02bc3837fe7fe96","execution_count":null},{"cell_type":"markdown","source":["The process has been interrupted by the api after 800 messages."],"metadata":{"collapsed":false,"id":"3cdbfb703dc67ed4"},"id":"3cdbfb703dc67ed4"},{"cell_type":"markdown","source":["Now save the responses to a local csv file."],"metadata":{"collapsed":false,"id":"79559c5694139e9a"},"id":"79559c5694139e9a"},{"cell_type":"code","outputs":[],"source":["data = data[0:800]\n","data.loc[:, 'gpt_label'] = responses\n","data['gpt_label'] = data['gpt_label'].astype(int)\n","data.to_csv(\"../data/test/800_test_labeled_gpt.csv\", index=False)"],"metadata":{"id":"d6ede1e0468da09f"},"id":"d6ede1e0468da09f","execution_count":null},{"cell_type":"markdown","source":["Calculate the F1 Score for the GPT-3 labels"],"metadata":{"collapsed":false,"id":"6ece771d4dc65373"},"id":"6ece771d4dc65373"},{"cell_type":"code","outputs":[{"data":{"text/plain":"0.8215979843308009"},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import f1_score\n","\n","f1_score(data['label'], data['gpt_label'], average='weighted')"],"metadata":{"ExecuteTime":{"end_time":"2024-03-21T12:27:47.423966Z","start_time":"2024-03-21T12:27:47.407872Z"},"id":"a75315276eeda5ec","outputId":"ede1021e-17a6-423e-d23c-d73ce8130c46"},"id":"a75315276eeda5ec","execution_count":null},{"cell_type":"markdown","source":["The F1Score is 0.82 which is a relatively good score. Now we'll try to outperform this score using a our BERT transformer model."],"metadata":{"collapsed":false,"id":"c1dfa1abbd538e04"},"id":"c1dfa1abbd538e04"},{"cell_type":"code","source":["from google.colab import drive\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import f1_score\n","from transformers import BertForSequenceClassification\n","import numpy as np\n","import os  # Importiert das OS-Modul\n","import pandas as pd  # FÃ¼r das Einlesen der CSV-Datei\n","from transformers import BertTokenizer\n","from tqdm import tqdm\n","\n","# Google Drive einbinden\n","drive.mount('/content/drive')\n","base_path = '/content/drive/My Drive/'\n","test_data_path = os.path.join(base_path, 'NLP/hate_speech_detection_pipeline/data/test/800_test_labeled_gpt.csv')\n","model_path = os.path.join(base_path, 'NLP/hate_speech_detection_pipeline/model/model2.pth')  # Pfad zum Modell aktualisiert\n","\n","# Zuerst das Modell initialisieren (stellen Sie sicher, dass die Modellklasse importiert oder definiert ist)\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","model.eval()\n","\n","# Testdaten laden\n","df = pd.read_csv(test_data_path)\n","\n","# Tokenisierung der Testdaten\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","tokenized_data = tokenizer(list(df['comment_text']), padding=True, truncation=True, return_tensors=\"pt\")\n","\n","# Labels in Tensor umwandeln\n","labels = torch.tensor(df['label'].values)\n","\n","# Erstellen des DataLoader\n","test_dataset = TensorDataset(tokenized_data['input_ids'], tokenized_data['attention_mask'], labels)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Modell evaluieren\n","model.eval()\n","all_preds = []\n","all_labels = []\n","with torch.no_grad():\n","    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n","        # Extrahieren der Daten aus dem Batch\n","        inputs, masks, labels = batch\n","        inputs, masks, labels = inputs.to('cpu'), masks.to('cpu'), labels.to('cpu')\n","\n","        # Modellvorhersage\n","        outputs = model(inputs, attention_mask=masks)\n","\n","        # Vorhersagen extrahieren\n","        _, predicted = torch.max(outputs.logits, dim=1)\n","\n","        # Ergebnisse sammeln\n","        all_preds.extend(predicted.tolist())\n","        all_labels.extend(labels.tolist())\n","\n","# F1-Score berechnen\n","f1 = f1_score(all_labels, all_preds, average='weighted')\n","print(f'F1 Score: {f1}')"],"metadata":{"id":"ujutCibCe-lF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2389fea4-9e5b-46eb-c445-0488773f7780"},"id":"ujutCibCe-lF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Evaluating:   0%|          | 0/13 [00:00<?, ?it/s]"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}